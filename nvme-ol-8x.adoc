---
sidebar: sidebar 
permalink: nvme-ol-8x.html 
keywords: nvme, oracle linux, 8.x, host configuration 
summary: Configuração de host NVMe-oF para Oracle Linux 8.x com ONTAP 
---
= Configure o Oracle Linux 8.x com NVMe-oF para armazenamento ONTAP.
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Os hosts Oracle Linux suportam os protocolos NVMe sobre Fibre Channel (NVMe/FC) e NVMe sobre TCP (NVMe/TCP) com Acesso Assimétrico ao Espaço de Nomes (ANA). O ANA fornece funcionalidade de múltiplos caminhos equivalente ao acesso de unidade lógica assimétrica (ALUA) em ambientes iSCSI e FCP.

Aprenda como configurar hosts NVMe over Fabrics (NVMe-oF) para Oracle Linux 8.x. Para obter mais informações sobre suporte e funcionalidades, consulte link:nvme-ol-supported-features.html["Suporte e recursos do Oracle Linux ONTAP"].

O NVMe-oF com Oracle Linux 8.x apresenta as seguintes limitações conhecidas:

* A inicialização de SAN usando o protocolo NVMe-oF não é suportada.
* O utilitário de host NetApp sanlun não oferece suporte a NVMe-oF em um host Oracle Linux 8.x. Em vez disso, você pode contar com o plug-in NetApp incluído no nativo `nvme-cli` pacote para todos os transportes NVMe-oF.
* Para o Oracle Linux 8.2 e versões anteriores, os scripts nativos de conexão automática NVMe/FC não estão disponíveis no pacote nvme-cli.  Utilize os scripts de conexão automática externa fornecidos pelo fornecedor do HBA.
* Para o Oracle Linux 8.2 e versões anteriores, o balanceamento de carga round-robin não está habilitado por padrão para multipathing NVMe.  Para ativar essa funcionalidade, vá para a etapa para<<udev-rule,Escrevendo uma regra udev>> .




== Passo 1: Instale o Oracle Linux e o software NVMe e verifique sua configuração.

Utilize o procedimento a seguir para validar as versões mínimas de software suportadas pelo Oracle Linux 8.x.

.Passos
. Instale o Oracle Linux 8.x no servidor. Após a conclusão da instalação, verifique se você está executando o kernel Oracle Linux 8.x especificado.
+
[source, cli]
----
uname -r
----
+
Exemplo de versão do kernel do Oracle Linux:

+
[listing]
----
5.15.0-206.153.7.1.el8uek.x86_64
----
. Instale o `nvme-cli` pacote:
+
[source, cli]
----
rpm -qa|grep nvme-cli
----
+
O exemplo a seguir mostra um  `nvme-cli` versão do pacote:

+
[listing]
----
nvme-cli-1.16-9.el8.x86_64
----
. [[udev-rule]] Para o Oracle Linux 8.2 e versões anteriores, adicione a seguinte string como uma regra udev separada para `/lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules` .  Isso permite o balanceamento de carga round-robin para NVMe multipath.
+
[source, cli]
----
cat /lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules
Enable round-robin for NetApp ONTAP
ACTION=="add", SUBSYSTEMS=="nvme-subsystem", ATTRS{model}=="NetApp ONTAP Controller", ATTR{iopolicy}="round-robin"
----
. No host Oracle Linux 8.x, verifique o `hostnqn` corda em `/etc/nvme/hostnqn` :
+
[source, cli]
----
cat /etc/nvme/hostnqn
----
+
O exemplo a seguir mostra um  `hostnqn` versão:

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
----
. No sistema ONTAP , verifique se o `hostnqn` A string corresponde à `hostnqn` string para o subsistema correspondente no sistema de armazenamento ONTAP :
+
[source, cli]
----
vserver nvme subsystem host show -vserver vs_coexistence_LPE36002
----
+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
Vserver Subsystem Priority  Host NQN
------- --------- --------  ------------------------------------------------
vs_coexistence_LPE36002
        nvme
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme1
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme2
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme3
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
4 entries were displayed.
----
====
+

NOTE: Se as `hostnqn` strings não corresponderem, use o `vserver modify` comando para atualizar a `hostnqn` cadeia de carateres no subsistema de matriz ONTAP correspondente para corresponder à `hostnqn` cadeia de carateres `/etc/nvme/hostnqn` do host.

. Opcionalmente, para executar tráfego NVMe e SCSI coexistentes no mesmo host, a NetApp recomenda o uso do multipath NVMe no kernel para namespaces ONTAP . `dm-multipath` para LUNs ONTAP, respectivamente.  Isso deve excluir os namespaces do ONTAP de `dm-multipath` e prevenir `dm-multipath` impedindo a reivindicação de dispositivos de namespace ONTAP .
+
.. Adicione o `enable_foreign` definindo para o `/etc/multipath.conf` arquivo.
+
[source, cli]
----
cat /etc/multipath.conf
defaults {
  enable_foreign     NONE
}
----
.. Reinicie o `multipathd` daemon para aplicar a nova configuração.
+
[source, cli]
----
systemctl restart multipathd
----






== Etapa 2: Configurar NVMe/FC e NVMe/TCP

Configure NVMe/FC com adaptadores Broadcom/Emulex ou Marvell/QLogic, ou configure NVMe/TCP usando operações manuais de descoberta e conexão.

[role="tabbed-block"]
====
.FC - Broadcom/Emulex
--
Configurar o NVMe/FC para um adaptador Broadcom/Emulex.

.Passos
. Verifique se você está usando o modelo de adaptador suportado:
+
.. Exibir os nomes dos modelos:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/modelname
----
+
Você deve ver a seguinte saída:

+
[listing]
----
LPe36002-M64
LPe36002-M64
----
.. Exibir as descrições do modelo:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/modeldesc
----
+
Você deverá ver uma saída semelhante ao exemplo a seguir:

+
[listing]
----
Emulex LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
Emulex LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
----


. Verifique se você está usando o firmware Broadcom recomendado e o driver da `lpfc` caixa de entrada:
+
.. Exibir a versão do firmware:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/fwrev
----
+
O exemplo a seguir mostra as versões de firmware:

+
[listing]
----
14.4.317.10, sli-4:6:d
14.4.317.10, sli-4:6:d
----
.. Exibir a versão do driver da caixa de entrada:
+
[source, cli]
----
cat /sys/module/lpfc/version
----
+
O exemplo a seguir mostra uma versão do driver:

+
[listing]
----
0:14.2.0.13
----
+
Para obter a lista atual de versões de firmware e drivers de adaptador suportados, consulte link:https://mysupport.netapp.com/matrix/["Ferramenta de Matriz de interoperabilidade"^].



. Verifique se `lpfc_enable_fc4_type` está definido como "3":
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
----
. Verifique se você pode exibir suas portas do iniciador:
+
[source, cli]
----
cat /sys/class/fc_host/host*/<port_name>
----
+
O exemplo a seguir mostra identidades de porta:

+
[listing]
----
0x100000109bf0449c
0x100000109bf0449d
----
. Verifique se as portas do iniciador estão online:
+
[source, cli]
----
cat /sys/class/fc_host/host*/port_state
----
+
Você deve ver a seguinte saída:

+
[listing]
----
Online
Online
----
. Verifique se as portas do iniciador NVMe/FC estão ativadas e se as portas de destino estão visíveis:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/nvme_info
----
+
.Mostrar exemplo
[%collapsible]
=====
[listing, subs="+quotes"]
----
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109bf0449c WWNN x200000109bf0449c DID x061500 *ONLINE*
NVME RPORT       WWPN x200bd039eab31e9c WWNN x2005d039eab31e9c DID x020e06 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2006d039eab31e9c WWNN x2005d039eab31e9c DID x020a0a *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000002c Cmpl 000000002c Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000008ffe8 Issue 000000000008ffb9 OutIO ffffffffffffffd1
        abort 0000000c noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 0000000c Err 0000000c
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109bf0449d WWNN x200000109bf0449d DID x062d00 *ONLINE*
NVME RPORT       WWPN x201fd039eab31e9c WWNN x2005d039eab31e9c DID x02090a *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x200cd039eab31e9c WWNN x2005d039eab31e9c DID x020d06 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000041 Cmpl 0000000041 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 00000000000936bf Issue 000000000009369a OutIO ffffffffffffffdb
        abort 00000016 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000016 Err 00000016
----
=====


--
.FC - Marvell/QLogic
--
Configure o NVMe/FC para um adaptador Marvell/QLogic.

.Passos
. Verifique se você está executando o driver de adaptador e as versões de firmware compatíveis:
+
[source, cli]
----
cat /sys/class/fc_host/host*/symbolic_name
----
+
O exemplo a seguir mostra as versões do driver e do firmware:

+
[listing]
----
QLE2772 FW:v9.15.00 DVR:v10.02.09.100-k
QLE2772 FW:v9.15.00 DVR:v10.02.09.100-k
----
. Verifique se `ql2xnvmeenable` está definido. Isso permite que o adaptador Marvell funcione como um iniciador NVMe/FC:
+
[source, cli]
----
cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
----
+
A saída esperada é 1.



--
.TCP
--
O protocolo NVMe/TCP não suporta a operação de conexão automática.  Em vez disso, você pode descobrir os subsistemas e namespaces NVMe/TCP executando o NVMe/TCP `connect` ou `connect-all` operações manualmente.

. Verifique se a porta do iniciador pode buscar os dados da página de log de descoberta nas LIFs NVMe/TCP suportadas:
+
[source, cli]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
.Mostrar exemplo
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.24 Discovery Log Number of Records 20, Generation counter 45
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  6
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.6.25
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  1
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.5.24
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  4
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.6.24
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  2
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.5.25
sectype: none
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  6
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
traddr:  192.168.6.25
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  1
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
..........
----
=====
. Verifique se todas as outras combinações de LIF de destino de iniciador NVMe/TCP podem obter com êxito os dados da página de log de descoberta:
+
[source, cli]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
.Mostrar exemplo
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.24
nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.25
nvme discover -t tcp -w 192.168.5.1 -a 192.168.5.24
nvme discover -t tcp -w 192.168.5.1 -a 192.168.5.25
----
=====
. Execute o `nvme connect-all` comando em todos os LIFs de destino iniciador NVMe/TCP suportados nos nós:
+
[source, cli]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l <ctrl_loss_timeout_in_seconds>
----
+
.Mostrar exemplo
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme	connect-all	-t	tcp	-w	192.168.5.1	-a	192.168.5.24	-l -1
nvme	connect-all	-t	tcp	-w	192.168.5.1	-a	192.168.5.25	-l -1
nvme	connect-all	-t	tcp	-w	192.168.6.1	-a	192.168.6.24	-l -1
nvme	connect-all	-t	tcp	-w	192.168.6.1	-a	192.168.6.25	-l -1
----
=====


[NOTE]
====
A NetApp recomenda definir o `ctrl-loss-tmo option` para `-1` para que o iniciador NVMe/TCP tente se reconectar indefinidamente em caso de perda de conexão.

====
--
====


== Etapa 3: Opcionalmente, habilite a E/S de 1 MB para NVMe/FC.

O ONTAP relata um Tamanho Máximo de Transferência de Dados (MDTS) de 8 nos dados do Controlador de Identificação.  Isso significa que o tamanho máximo da solicitação de E/S pode ser de até 1 MB.  Para emitir solicitações de E/S de tamanho 1 MB para um host Broadcom NVMe/FC, você deve aumentar o `lpfc` valor do `lpfc_sg_seg_cnt` parâmetro para 256 do valor padrão de 64.


NOTE: Essas etapas não se aplicam a hosts Qlogic NVMe/FC.

.Passos
. Defina `lpfc_sg_seg_cnt` o parâmetro como 256:
+
[source, cli]
----
cat /etc/modprobe.d/lpfc.conf
----
+
Você deverá ver uma saída semelhante ao exemplo a seguir:

+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Execute o `dracut -f` comando e reinicie o host.
. Verifique se o valor para `lpfc_sg_seg_cnt` é 256:
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== Etapa 4: Verifique a configuração de multipathing

Verifique se o status multipath do NVMe no kernel, o status ANA e os namespaces do ONTAP estão corretos para a configuração do NVMe-of.

.Passos
. Verifique se o multipath NVMe no kernel está habilitado:
+
[source, cli]
----
cat /sys/module/nvme_core/parameters/multipath
----
+
Você deve ver a seguinte saída:

+
[listing]
----
Y
----
. Verifique se as configurações de NVMe-of apropriadas (como o modelo definido como controlador NetApp ONTAP e o balanceamento de carga iopolicy definido como round-robin) para os respetivos namespaces ONTAP refletem corretamente no host:
+
.. Exibir os subsistemas:
+
[source, cli]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/model
----
+
Você deve ver a seguinte saída:

+
[listing]
----
NetApp ONTAP Controller
NetApp ONTAP Controller
----
.. Exibir a política:
+
[source, cli]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
----
+
Você deve ver a seguinte saída:

+
[listing]
----
round-robin
round-robin
----


. Verifique se os namespaces são criados e descobertos corretamente no host:
+
[source, cli]
----
nvme list
----
+
.Mostrar exemplo
[%collapsible]
====
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme0n1 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n2 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n3 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller

Namespace Usage   Format               FW            Rev
-----------------------------------------------------------
1                 85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF
2                 85.90 GB / 85.90 GB  24 KiB + 0 B  FFFFFFFF
3	                85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF

----
====
. Verifique se o estado do controlador de cada caminho está ativo e tem o status ANA correto:
+
[source, cli]
----
nvme list-subsys /dev/nvme0n1
----
+
.Mostrar exemplo de NVMe/FC
[%collapsible]
====
[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992- 08.com.netapp: 4b4d82566aab11ef9ab8d039eab31e9d:subsystem.nvme\
+-  nvme1 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203ad039eab31e9c host_traddr=nn-0x200034800d756a89:pn-0x210034800d756a89 *live optimized*
+-  nvme2 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203cd039eab31e9c host_traddr=nn-0x200034800d756a88:pn-0x210034800d756a88 *live optimized*
+- nvme3 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203ed039eab31e9c host_traddr=nn-0x200034800d756a89:pn-0x210034800d756a89 *live non-optimized*
+-  nvme7 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x2039d039eab31e9c host_traddr=nn-0x200034800d756a88:pn-0x210034800d756a88 *live non-optimized*
----
====
+
.Mostrar exemplo de NVMe/TCP
[%collapsible]
====
[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992- 08.com.netapp: sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
\
+- nvme1 *tcp* traddr=192.168.5.25 trsvcid=4420 host_traddr=192.168.5.1 src_addr=192.168.5.1 *live optimized*
+- nvme10 *tcp* traddr=192.168.6.24 trsvcid=4420 host_traddr=192.168.6.1 src_addr=192.168.6.1 *live optimized*
+- nvme2 *tcp* traddr=192.168.5.24 trsvcid=4420 host_traddr=192.168.5.1 src_addr=192.168.5.1 *live non-optimized*
+- nvme9 *tcp* traddr=192.168.6.25 trsvcid=4420 host_traddr=192.168.6.1 src_addr=192.168.6.1 *live non-optimized*
----
====
. Verifique se o plug-in NetApp exibe os valores corretos para cada dispositivo de namespace ONTAP:
+
[role="tabbed-block"]
====
.Coluna
--
[source, cli]
----
nvme netapp ontapdevices -o column
----
.Mostrar exemplo
[%collapsible]
=====
[listing, subs="+quotes"]
----
Device         Vserver                  Namespace Path                NSID UUID                                  Size
-------------- ------------------------ ----------------------------- ---- ------------------------------------- ---------
/dev/nvme0n1   vs_coexistence_QLE2772   /vol/fcnvme_1_1_0/fcnvme_ns   1    159f9f88-be00-4828-aef6-197d289d4bd9  10.74GB
/dev/nvme0n2   vs_coexistence_QLE2772   /vol/fcnvme_1_1_1/fcnvme_ns   2    2c1ef769-10c0-497d-86d7-e84811ed2df6  10.74GB
/dev/nvme0n3   vs_coexistence_QLE2772   /vol/fcnvme_1_1_2/fcnvme_ns   3    9b49bf1a-8a08-4fa8-baf0-6ec6332ad5a4  10.74GB
----
=====
--
.JSON
--
[source, cli]
----
nvme netapp ontapdevices -o json
----
.Mostrar exemplo
[%collapsible]
=====
[listing, subs="+quotes"]
----
{
  "ONTAPdevices" : [
    {
      "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_0/fcnvme_ns",
      "NSID" : 1,
      "UUID" : "159f9f88-be00-4828-aef6-197d289d4bd9",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
    {
      "Device" : "/dev/nvme0n2",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_1/fcnvme_ns",
      "NSID" : 2,
      "UUID" : "2c1ef769-10c0-497d-86d7-e84811ed2df6",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
    {
      "Device" : "/dev/nvme0n4",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_3/fcnvme_ns",
      "NSID" : 4,
      "UUID" : "f3572189-2968-41bc-972a-9ee442dfaed7",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
----
=====
--
====




== Etapa 5: Opcionalmente, habilite o tamanho de E/S de 1 MB.

O ONTAP relata um Tamanho Máximo de Transferência de Dados (MDTS) de 8 nos dados do Controlador de Identificação.  Isso significa que o tamanho máximo da solicitação de E/S pode ser de até 1 MB.  Para emitir solicitações de E/S de tamanho 1 MB para um host Broadcom NVMe/FC, você deve aumentar o `lpfc` valor do `lpfc_sg_seg_cnt` parâmetro para 256 do valor padrão de 64.


NOTE: Essas etapas não se aplicam a hosts Qlogic NVMe/FC.

.Passos
. Defina `lpfc_sg_seg_cnt` o parâmetro como 256:
+
[source, cli]
----
cat /etc/modprobe.d/lpfc.conf
----
+
Você deverá ver uma saída semelhante ao exemplo a seguir:

+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Execute o `dracut -f` comando e reinicie o host.
. Verifique se o valor para `lpfc_sg_seg_cnt` é 256:
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== Passo 6: Revise os problemas conhecidos

Estes são os problemas conhecidos:

[cols="20,40,40"]
|===
| ID de erro do NetApp | Título | Descrição 


| link:https://mysupport.netapp.com/site/bugs-online/product/HOSTUTILITIES/BURT/1479047["1479047"^] | Os hosts Oracle Linux 8.x NVMe-oF criam controladores de descoberta persistente (PDCs) duplicados. | Em hosts NVMe-oF, você pode usar o comando `nvme discover -p`  para criar PDCs. Ao utilizar este comando, apenas um PDC deve ser criado por combinação iniciador-alvo. No entanto, se você estiver executando o Oracle Linux 8.x com um host NVMe-oF, um PDC duplicado será criado sempre que `nvme discover -p` for executado. Isso leva ao uso desnecessário de recursos tanto no host quanto no destino. 
|===